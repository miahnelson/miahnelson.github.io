{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\miahn\\\\Documents\\\\PyCode\\\\Jupyter\\\\LAS\\\\9094449~XTO Energy~Lawson 5-13H14X~DEPTH'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lasio\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import os\n",
    "pth = r'C:\\Users\\miahn\\Documents\\PyCode\\Jupyter\\LAS\\9094449~XTO~LawsonÂ 5-13H14X~20181018174046~FINAL_FILES_LAS_TIME~189912300000~196202021800~TM.las'\n",
    "\n",
    "las = lasio.read(pth)\n",
    "\n",
    "# Now we create the root name for all output files for use later on\n",
    "originalPath = os.path.dirname(pth)\n",
    "fName = os.path.basename(pth)\n",
    "jobNumber = fName[:fName.find('~')]\n",
    "operatorName = las.well['COMP'].value\n",
    "wellName = las.well['WELL'].value\n",
    "rootName = originalPath +'\\\\%s~%s~%s~DEPTH' % (jobNumber, operatorName, wellName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = las.df()\n",
    "# Drop columns and rows that only have null values\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "# Make TIME the index\n",
    "df.index.names = ['TIME']\n",
    "\n",
    "# Keep only drilling rows\n",
    "df.drop(df[(df['RIGSTAT'] != 111) & (df['RIGSTAT'] != 11)].index, inplace=True)\n",
    "''' There is an error in Cadence where it sometimes creates a Hole Depth in the millions. \n",
    "The bit depth however appears to be correct in these cases. To account for this we \n",
    "replace the value of Depth with Bit Depth. This should not cause an issue as we have \n",
    "already dropped non drilling rows, so Bit Depth and Hole Depth should be equal '''\n",
    "df.DEPTH[df.DEPTH > 50000] = df.BITDEP\n",
    "\n",
    "'''Just in case the above does not work, remove any row with a Hole Depth greater than 50k'''\n",
    "df.drop(df[(df['DEPTH'] > 50000)].index, inplace=True)\n",
    "\n",
    "'''Now we need to aggregate the data in 1 foot intervals. For this we chose to get the max\n",
    "value for the aggregated data to see worst case scenerio for each foot.'''\n",
    "\n",
    "# The first step is to make each depth a single foot. I am rounding the numbers here, but it might be better \n",
    "# to truncate or round up. We will have to experiment to figure that out.\n",
    "df = df.round({'DEPTH': 0}) \n",
    "\n",
    "# After that we group the values by DEPTH\n",
    "df = df.groupby(['DEPTH']).max()\n",
    "\n",
    "'''LAS files require a uniform step value. WellCAD requires a uniform step value for well log data. The \n",
    "above can very easily leave depths out during areas with high rate of penetration. We need to fill in \n",
    "these missing depths. This will of course leave null values for everything except the depth int the new \n",
    "rows. We might consider interpolation later, however this will suffice to make the LAS file standard \n",
    "and WellCAD happy.'''\n",
    "# Create a new index from the current index min and max, incrementing by 1. This will overwrite the \n",
    "# current index which was set to the DEPTH column when we grouped earlier, so we name the new index DEPTH\n",
    "new_index = pd.Index(np.arange(df.index.min(),df.index.max(),1), name=\"DEPTH\").astype(int) \n",
    "\n",
    "# Set the the index to our newly created index. Pandas will automatically expand all the available rows to this \n",
    "# new index based on the values in the old index\n",
    "\n",
    "df = df.reindex(new_index)\n",
    "# We reset the index here so that the new DEPTH index is moved back to the columns\n",
    "df = df.reset_index()\n",
    "\n",
    "# Output to csv just so we can compare to the LAS file later\n",
    "df.to_csv(rootName + '.csv',  encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Congratulations! You should have a depth based LAS file created from a Unix Time based LAS file'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This is where things get a bit more complicated. We have the mnemonic names as our dataframe column headers, \n",
    "but the dataframe has no idea what the unit types are. Luckily the original LAS file does and the lasio \n",
    "library stores this information in the las file we originally read. \n",
    "\n",
    "Our goal is to compare the dataframes column names, extract only the items we want, change the values that need \n",
    "to be changed such as creation date, step value, presentation name, etc.'''\n",
    "\n",
    "# Create a new LAS file and setup header\n",
    "depthlas = lasio.LASFile()\n",
    "depthlas.well.DATE = str(datetime.today())\n",
    "depthlas.well.STRT = lasio.HeaderItem('STRT', 'ft', df.index.min(), 'START DEPTH')\n",
    "depthlas.well.STOP = lasio.HeaderItem('STOP', 'ft', df.index.max(), 'STOP DEPTH')\n",
    "depthlas.well.STEP = lasio.HeaderItem('STEP', 'ft', 1, 'STEP')\n",
    "depthlas.well.NULL = lasio.HeaderItem('NULL', '', -999.25, 'Null Value')\n",
    "depthlas.well.DATE = str(datetime.today())\n",
    "\n",
    "# Add items from old header to new header\n",
    "'''These are the options we want to ignore.'''\n",
    "ignorelist = ['STRT', 'STOP', 'STEP', 'NULL', 'TITL', 'TIME', 'DATE']\n",
    "\n",
    "# Add/Modify Well section\n",
    "oldMnemonics =[]\n",
    "for itm in las.well:\n",
    "    if itm.original_mnemonic.find(':')==-1 and itm.original_mnemonic not in ignorelist:\n",
    "        oldMnemonics.append(itm.original_mnemonic)\n",
    "for listItem in oldMnemonics:\n",
    "    depthlas.well[listItem] = las.well[listItem]\n",
    "\n",
    "# Add/Modify paramters section\n",
    "oldMnemonics =[]\n",
    "for itm in las.params:\n",
    "    if itm.original_mnemonic.find(':')==-1 and itm.original_mnemonic not in ignorelist:\n",
    "        oldMnemonics.append(itm.original_mnemonic)\n",
    "for listItem in oldMnemonics:\n",
    "    depthlas.params[listItem] = las.params[listItem]\n",
    "\n",
    "# Add data from dataframe\n",
    "colList = df.columns\n",
    "for col in colList:\n",
    "    depthlas.add_curve(col, df[col], unit=las.curves[col].unit, descr=las.curves[col].descr[las.curves[col].descr.find(' '):]) \n",
    "\n",
    "# display(depthlas.header)\n",
    "depthlas.write(rootName + '.las', version=2)\n",
    "'''Congratulations! You should have depth based LAS and CSV files created from a Unix Time based LAS file'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
